{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78696073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In logistic Regression, Hyper-parameter tuning is applied while calculating the z-score\n",
    "# \n",
    "#   - Here, we also have 3 kinds of regularization :-\n",
    "#       - L1 Regularization (Lasso)             {Feature Selectiom}\n",
    "#       - L2 Regularization (Ridge)             {Prevents Overfitting}\n",
    "#       - L1 & L2 Regularization (ElasticNet)   {Balance between L1&L2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e45ab6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python setting hyperparameters manually in LogisticRegression Class\n",
    "# \n",
    "# LogisticRegression (\n",
    "#       \"penalty\" : {'l1', 'l2', 'elasticnet'}\n",
    "#       \"tol\" : tolerance (stopping critera for error)\n",
    "#       \"C\" : Inverse of Regularization Strength(λ) (Smaller values imply stronger Regularization)\n",
    "#       \"class_weight\" : 'balanced' or dict{column_name: weight}\n",
    "#       \"solver\" : {‘lbfgs’, ‘liblinear’, ‘newton-cg’, ‘newton-cholesky’, ‘sag’, ‘saga’}\n",
    "#       \"max_iter\" : maximum iterations allowed in gradient descent\n",
    "#       \"n_jobs\" : maximum cores allowed to be used\n",
    "# ) -> {\n",
    "#       \"coeff_\" : coefficient array [β₀ β₁x₁ β₂x₂ ... βₙ]  {for each model in case of multi-class classification}\n",
    "#       \"intercept_\" : constant term                        {for each model in case of multi-class classification}\n",
    "# } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dec9f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Temperature</th>\n",
       "      <th>RH</th>\n",
       "      <th>WS</th>\n",
       "      <th>Rain</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>BUI</th>\n",
       "      <th>Fire</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "      <td>57</td>\n",
       "      <td>18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.7</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>3.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29</td>\n",
       "      <td>61</td>\n",
       "      <td>13</td>\n",
       "      <td>1.3</td>\n",
       "      <td>64.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>7.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>82</td>\n",
       "      <td>22</td>\n",
       "      <td>13.1</td>\n",
       "      <td>47.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>89</td>\n",
       "      <td>13</td>\n",
       "      <td>2.5</td>\n",
       "      <td>28.6</td>\n",
       "      <td>1.3</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>27</td>\n",
       "      <td>77</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>64.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Temperature  RH  WS  Rain  FFMC  DMC    DC  ISI  BUI  Fire\n",
       "0           29  57  18   0.0  65.7  3.4   7.6  1.3  3.4     0\n",
       "1           29  61  13   1.3  64.4  4.1   7.6  1.0  3.9     0\n",
       "2           26  82  22  13.1  47.1  2.5   7.1  0.3  2.7     0\n",
       "3           25  89  13   2.5  28.6  1.3   6.9  0.0  1.7     0\n",
       "4           27  77  16   0.0  64.8  3.0  14.2  1.2  3.9     0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./datasets/algerian-forest-fires-cleaned.csv')\n",
    "df.drop(['FWI'], axis = 1, inplace = True)\n",
    "df['Fire'] = df['Fire'].astype(int)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "355c451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, 0:-1]\n",
    "Y = df.iloc[:, -1]\n",
    "\n",
    "X_Train, X_Test, Y_Train, Y_Test = train_test_split(X, Y, test_size = 0.25, random_state = 10)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_Train = scaler.fit_transform(X_Train)\n",
    "X_Test = scaler.transform(X_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d228a05",
   "metadata": {},
   "source": [
    "## Automatic Hyperparameter Tuning and CV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa88ca4b",
   "metadata": {},
   "source": [
    "### 1. Using Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2271f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here the model is trained on all possible combinations of parameters specified and the best model trained for best parameter is returned\n",
    "# \n",
    "# Syntax :-\n",
    "# GridSearchCV(\n",
    "#     \"estimator\" : base_regression_model_object\n",
    "#     \"param_grid\" : json(parameter: list_of_values_to_search)\n",
    "#     \"scoring\" : method used to evaluate model performance while seach \n",
    "#               : {'accuracy', 'precision', 'recall', 'f1'}\n",
    "#     \"refit\" : scoring method used to evaluate the model if multiple \"scoring\" methods is passed\n",
    "#     \"cv\" : no_of_folds (here, StratifiedKFold)\n",
    "#     \"n_jobs\" : no of processors\n",
    "#     \"error_score\" : score to set for a incompatible combination occured \n",
    "#                   : (\"ignore\"/\"raise\")\n",
    "# ) -> {\n",
    "#     \"cv_results\" : overall summary  of cv\n",
    "#     \"best_params_\" : best parameters which got selected in \"params_grid\"\n",
    "#     \"best_score_\" : best score for model obtained using performance metrics specified in \"scoring\"\n",
    "#     \"best_estimator_\" : returns the best model trained\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3361b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Selected:\n",
      " {'C': 0.1, 'l1_ratio': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "\n",
      "Best Accuracy on Test Data: 0.9344262295081968\n",
      "Best Accuracy on Train Data: 0.989010989010989\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# ignore the warning for failed fits (invalid search param combinations)\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "\n",
    "# specify the base estimator\n",
    "base_estimator = LogisticRegression(max_iter = 5000, n_jobs = -1)\n",
    "\n",
    "# specify the range of parameters for tuning on the base_estimator\n",
    "search_parameters_on_base_estimator = {\n",
    "    \"penalty\": ['l1', 'l2', 'elasticnet'],\n",
    "    \"C\" : [10, 5, 2, 1, 0.5, 0.1],\n",
    "    \"solver\" : ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "    \"l1_ratio\": [0.1, 0.5, 0.75, 1, 2, 4, 10]\n",
    "}\n",
    "\n",
    "# make gridsearchcv object\n",
    "gridsearch = GridSearchCV(\n",
    "    estimator = base_estimator,\n",
    "    param_grid = search_parameters_on_base_estimator,\n",
    "    scoring = ['recall', 'accuracy', 'precision'],\n",
    "    refit = 'accuracy',\n",
    "    cv = 5,\n",
    "    n_jobs = -1,\n",
    "    error_score = 0\n",
    ")\n",
    "\n",
    "# train the model \n",
    "# (search for best model which fits the data by trying all possible combinations of parameters)\n",
    "gridsearch.fit(X_Train, Y_Train)\n",
    "\n",
    "print('Best Parameters Selected:\\n', gridsearch.best_params_)\n",
    "print()\n",
    "print('Best Accuracy on Test Data:', gridsearch.score(X_Test, Y_Test))\n",
    "print('Best Accuracy on Train Data:', gridsearch.score(X_Train, Y_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "773218c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[22  1]\n",
      " [ 3 35]]\n",
      "\n",
      "For Test Dataset\n",
      "Accuracy: 0.9344262295081968\n",
      "Precision: 0.9722222222222222\n",
      "Recall: 0.9210526315789473\n",
      "\n",
      "For Training Dataset\n",
      "Accuracy: 0.989010989010989\n",
      "Precision: 0.98989898989899\n",
      "Recall: 0.98989898989899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prediction \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "Y_Pred = gridsearch.predict(X_Test)\n",
    "\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_Test, Y_Pred))\n",
    "print()\n",
    "\n",
    "# Prediction on Test Data\n",
    "print('For Test Dataset')\n",
    "print('Accuracy:', accuracy_score(Y_Test, Y_Pred))\n",
    "print('Precision:', precision_score(Y_Test, Y_Pred))\n",
    "print('Recall:', recall_score(Y_Test, Y_Pred))\n",
    "print()\n",
    "\n",
    "# Prediction on Train Data\n",
    "Y_Pred = gridsearch.predict(X_Train)\n",
    "print('For Training Dataset')\n",
    "print('Accuracy:', accuracy_score(Y_Train, Y_Pred))\n",
    "print('Precision:', precision_score(Y_Train, Y_Pred))\n",
    "print('Recall:', recall_score(Y_Train, Y_Pred))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d28b8",
   "metadata": {},
   "source": [
    "### 2. Using Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2eafeb8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Selected:\n",
      " {'solver': 'lbfgs', 'penalty': 'l2', 'l1_ratio': 1, 'C': 10}\n",
      "\n",
      "Best Accuracy on Test Data: 0.9344262295081968\n",
      "Best Accuracy on Train Data: 0.989010989010989\n"
     ]
    }
   ],
   "source": [
    "# Here the model is trained on random combinations of parameters specified and the best model trained for best parameter is returned\n",
    "# It is little faster than GridSearchCV\n",
    "# Same Syntax as GridSearchCV\n",
    "#       - One difference : use param_distributions instead of param_grid\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import FitFailedWarning\n",
    "warnings.filterwarnings(\"ignore\", category=FitFailedWarning)\n",
    "warnings.filterwarnings(\"ignore\", category = UserWarning)\n",
    "\n",
    "# specify the base estimator\n",
    "base_estimator = LogisticRegression(max_iter = 5000, n_jobs = -1)\n",
    "\n",
    "# specify the range of parameters for tuning on the base_estimator\n",
    "search_parameters_on_base_estimator = {\n",
    "    \"penalty\": ['l1', 'l2', 'elasticnet'],\n",
    "    \"C\" : [10, 5, 2, 1, 0.5, 0.1],\n",
    "    \"solver\" : ['lbfgs', 'liblinear', 'newton-cg', 'sag', 'saga'],\n",
    "    \"l1_ratio\": [0.1, 0.25, 0.5, 0.75, 0.9, 1]\n",
    "}\n",
    "\n",
    "# make randomizedsearchsv object\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "randomsearch = RandomizedSearchCV(\n",
    "    estimator = base_estimator,\n",
    "    param_distributions = search_parameters_on_base_estimator,\n",
    "    scoring = ['recall', 'accuracy', 'precision'],\n",
    "    refit = 'accuracy',\n",
    "    cv = 5,\n",
    "    n_jobs = -1,\n",
    "    error_score = 0\n",
    ")\n",
    "\n",
    "# train the model \n",
    "# (search for best model which fits the data by trying all possible combinations of parameters)\n",
    "randomsearch.fit(X_Train, Y_Train)\n",
    "\n",
    "print('Best Parameters Selected:\\n', randomsearch.best_params_)\n",
    "print()\n",
    "print('Best Accuracy on Test Data:', randomsearch.score(X_Test, Y_Test))\n",
    "print('Best Accuracy on Train Data:', randomsearch.score(X_Train, Y_Train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f320e87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[23  0]\n",
      " [ 4 34]]\n",
      "\n",
      "For Test Dataset\n",
      "Accuracy: 0.9344262295081968\n",
      "Precision: 1.0\n",
      "Recall: 0.8947368421052632\n",
      "\n",
      "For Training Dataset\n",
      "Accuracy: 0.989010989010989\n",
      "Precision: 0.98989898989899\n",
      "Recall: 0.98989898989899\n"
     ]
    }
   ],
   "source": [
    "# Prediction \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "Y_Pred = randomsearch.predict(X_Test)\n",
    "\n",
    "print('Confusion Matrix:\\n', confusion_matrix(Y_Test, Y_Pred))\n",
    "print()\n",
    "\n",
    "# Prediction on Test Data\n",
    "print('For Test Dataset')\n",
    "print('Accuracy:', accuracy_score(Y_Test, Y_Pred))\n",
    "print('Precision:', precision_score(Y_Test, Y_Pred))\n",
    "print('Recall:', recall_score(Y_Test, Y_Pred))\n",
    "print()\n",
    "\n",
    "# Prediction on Train Data \n",
    "Y_Pred = randomsearch.predict(X_Train)\n",
    "print('For Training Dataset')\n",
    "print('Accuracy:', accuracy_score(Y_Train, Y_Pred))\n",
    "print('Precision:', precision_score(Y_Train, Y_Pred))\n",
    "print('Recall:', recall_score(Y_Train, Y_Pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "270da32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all the models\n",
    "\n",
    "import pickle\n",
    "pickle.dump(scaler, file = open('.\\\\models\\\\class-predictors\\\\scaler.pkl', 'wb'))\n",
    "pickle.dump(gridsearch.best_estimator_, file = open('.\\\\models\\\\class-predictors\\\\gridsearch.pkl', 'wb'))\n",
    "pickle.dump(randomsearch.best_estimator_, file = open('.\\\\models\\\\class-predictors\\\\randomsearch.pkl', 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
